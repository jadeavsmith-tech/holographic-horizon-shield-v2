from textattack import AttackArgs, Attacker
from textattack.attack_recipes import PWWSRen2019
from textattack.models.wrappers import HuggingFaceModelWrapper
from transformers import AutoModelForSequenceClassification, AutoTokenizer

# Setup a dummy classifier for simulation (replace with Phi if GPU-heavy)
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-finetuned-sst-2-english")
model_wrapper = HuggingFaceModelWrapper(model, tokenizer)

# Attack recipe (word swap for adversarial examples)
recipe = PWWSRen2019.build(model_wrapper)

# Simulate attack on a prompt
attack_args = AttackArgs(num_examples=5, log_to_txt="attack_log.txt")
attacker = Attacker(recipe, model_wrapper, attack_args=attack_args)
results = attacker.attack_dataset([("Tell me a fun fact about space.", 1)])  # Example input

for result in results:
    print(result.original_text())
    print("â†’ Adversarial:", result.perturbed_text())
    print("Shield Test: Would this bypass? (Run boundary_scan on perturbed text)")
