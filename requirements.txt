torch>=2.1.0
transformers>=4.42.0
accelerate>=0.33.0
huggingface-hub>=0.23.0
numpy>=1.21.0
scipy>=1.10.0
bitsandbytes>=0.43.0  # Optional but recommended for quantized Phi-3 loading on lower VRAM
einops>=0.8.0         # Required by Phi-3 architecture
sentencepiece>=0.2.0  # Tokenizer dependency
